{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# 4.3 Detector & Descriptor Benchmarking\n\nNow we have met some of the most interesting keypoint detectors and descriptors, it would be interesting to test them and compare their results in terms of number of detections, robustness, invariance and performance. In the context of our photo-stitching application, not all the keypoint detectors and descriptors seem to perform the same.\n\nThus, in this notebook, you are asked to evaluate the following methods:\n\n- Harris + NCC\n- Harris + ORB (descriptor)\n- ORB \n- SIFT\n- SURF\n\nin images that suffer changes in:\n\n- lighting conditions\n- rotation\n- scale\n- point of view\n\nSo, for each situation, you'll be provided with a pair of images that you will have to use to detect, describe and match the above-mentioned keypoints. After that, provide and plot in a bar chart the following statistics:\n\n- average number of keypoints detected in the images\n- number of found matches\n- time spent per keypoint at detection (including description)*\n- time spent per match during matching*\n\n*use `time.process_time()` from the [`time`](https://docs.python.org/3/library/time.html) package to measure time."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# preamble\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport time\nmatplotlib.rcParams['figure.figsize'] = (20.0, 20.0)\nimages_path = './images/'\n\n# for sift\n# import sys\n# sys.path.append(\"..\")\n# from utils.third_party import pysift #https://github.com/rmislam/PythonSIFT",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Prepare output"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create output vectors\nstats_kps = np.zeros((4,5))\nstats_mat = np.zeros((4,5))\nstats_tdet = np.zeros((4,5))\nstats_tmat = np.zeros((4,5))",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Preliminary functions (brought from 4.1 and adapted)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Define a function to detect Harris\ndef detectHarris(image,w_size,sobel_size,k):\n    \"\"\" Detect Harris features, perform non-max-suppression and return it\n    \n        Args:\n                image: Input image\n                w_size: window size for blurring\n                sobel_size: window size for Sobel\n                k: Harris 'k' parameter\n        \n        Returns:\n                kps: list of 'cv2.KeyPoint' with the found keypoints\n    \"\"\"\n    # Write your code here!\n    # [...]\n    # return kps\n    \n# ... and another one to match them\ndef matchHarris(image_l,image_r,kps_l,kps_r):\n    \"\"\" Match Harris features using NCC, and return a list of 'cv2.DMatch'\n    \n        Args:\n                image_l: Input left image\n                image_r: Input right image\n                kps_l: List of keypoints for the left image\n                kps_r: List of keypoints for the right image\n        \n        Returns:\n                matches: list of 'cv2.DMatch' with the found matches\n    \"\"\"\n    # Write your code here!\n    # [...]\n    # return matches\n\n# This method has been provided to you in a previous notebook\nfrom scipy import signal\ndef nonmaxsuppts(cim, radius, thresh):\n    \"\"\" Binarize and apply non-maximum suppresion.   \n    \n        Args:\n            cim: the harris 'R' image\n            radius: the aperture size of local maxima window\n            thresh: the threshold value for binarization\n                    \n        Returns: \n            r, c: two numpy vectors being the row (r) and the column (c) of each keypoint\n    \"\"\"   \n    \n    rows, cols = np.shape(cim)\n    sze = 2 * radius + 1\n    mx = signal.order_filter(cim, np.ones([sze, sze]), sze ** 2 - 1)\n    bordermask = np.zeros([rows, cols]);\n    bordermask[radius:(rows - radius), radius:(cols - radius)] = 1\n    cim = np.array(cim)\n    r, c = np.where((cim == mx) & (cim > thresh) & (bordermask == 1))\n    return r, c",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Create a process function for each method"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def process_Harris_NCC(image_l, image_l_gray, image_r, image_r_gray):\n    \"\"\" Process all the Harris+NCC part for a pair of input images (in RGB and gray versions).\n    \n        Args:\n                image_l: Input left image (RGB)\n                image_l_gray: Input left image (grayscale)\n                image_r: Input right image\n                image_r_gray: Input right image (grayscale)\n        \n        Returns:\n                num_kps: average number of keypoints found in each image\n                num_matches: number of matches found\n                tdet: detection time per keypoint\n                tmat: matching time per match\n    \"\"\"\n    # Write your code here!\n    # [...]\n    # return num_kps, num_matches, tdet, tmat",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def process_Harris_ORB(image_l, image_l_gray, image_r, image_r_gray):\n    \"\"\" Process all the Harris+ORB part for a pair of input images (in RGB and gray versions).\n    \n        Args:\n                image_l: Input left image (RGB)\n                image_l_gray: Input left image (grayscale)\n                image_r: Input right image\n                image_r_gray: Input right image (grayscale)\n        \n        Returns:\n                num_kps: average number of keypoints found in each image\n                num_matches: number of matches found\n                tdet: detection time per keypoint\n                tmat: matching time per match\n    \"\"\"\n    # Write your code here!\n    # [...]\n    # return num_kps, num_matches, tdet, tmat",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def process_ORB(image_l, image_l_gray, image_r, image_r_gray):\n    \"\"\" Process all the ORB part for a pair of input images (in RGB and gray versions).\n    \n        Args:\n                image_l: Input left image (RGB)\n                image_l_gray: Input left image (grayscale)\n                image_r: Input right image\n                image_r_gray: Input right image (grayscale)\n        \n        Returns:\n                num_kps: average number of keypoints found in each image\n                num_matches: number of matches found\n                tdet: detection time per keypoint\n                tmat: matching time per match\n    \"\"\"\n    # Write your code here!\n    # [...]\n    # return num_kps, num_matches, tdet, tmat",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def process_SIFT(image_l, image_l_gray, image_r, image_r_gray):\n    \"\"\" Process all the SIFT part for a pair of input images (in RGB and gray versions).\n    \n        Args:\n                image_l: Input left image (RGB)\n                image_l_gray: Input left image (grayscale)\n                image_r: Input right image\n                image_r_gray: Input right image (grayscale)\n        \n        Returns:\n                num_kps: average number of keypoints found in each image\n                num_matches: number of matches found\n                tdet: detection time per keypoint\n                tmat: matching time per match\n    \"\"\"\n    # Write your code here!\n    # [...]\n    # return num_kps, num_matches, tdet, tmat",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def process_SURF(image_l, image_l_gray, image_r, image_r_gray):\n    \"\"\" Process all the SURF part for a pair of input images (in RGB and gray versions).\n    \n        Args:\n                image_l: Input left image (RGB)\n                image_l_gray: Input left image (grayscale)\n                image_r: Input right image\n                image_r_gray: Input right image (grayscale)\n        \n        Returns:\n                num_kps: average number of keypoints found in each image\n                num_matches: number of matches found\n                tdet: detection time per keypoint\n                tmat: matching time per match\n    \"\"\"\n    # Write your code here!\n    # [...]\n    # return num_kps, num_matches, tdet, tmat",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Exercise 1: Changes in ligthing conditions\nUse `bright1.png` and `bright2.png` images.\n\n<img src=\"./images/bright1.png\" width=\"300\" align=\"left\"/><img src=\"./images/bright2.png\" width=\"300\" align=\"rigth\"/>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Read images and convert them to gray (will be used for all the methods)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Write your code here!\n## Read images and convert them to gray\nimage_l = cv2.imread(images_path + 'bright1.png')\nimage_r = cv2.imread(images_path + 'bright2.png')\nimage_l = cv2.cvtColor(image_l,cv2.COLOR_BGR2RGB)\nimage_r = cv2.cvtColor(image_r,cv2.COLOR_BGR2RGB)\nimage_l_gray = cv2.cvtColor(image_l,cv2.COLOR_RGB2GRAY)\nimage_r_gray = cv2.cvtColor(image_r,cv2.COLOR_RGB2GRAY)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Make tests"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# HARRIS + NCC\n# stats_kps[0,0],stats_mat[0,0],stats_tdet[0,0],stats_tmat[0,0] = process_Harris_NCC(image_l, image_l_gray, image_r, image_r_gray)",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# HARRIS + ORB\n# stats_kps[0,1],stats_mat[0,1],stats_tdet[0,1],stats_tmat[0,1] = process_Harris_ORB(image_l, image_l_gray, image_r, image_r_gray)",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ORB\n# stats_kps[0,2],stats_mat[0,2],stats_tdet[0,2],stats_tmat[0,2] = process_ORB(image_l, image_l_gray, image_r, image_r_gray)",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# SIFT\n# stats_kps[0,3],stats_mat[0,3],stats_tdet[0,3],stats_tmat[0,3] = process_SIFT(image_l, image_l_gray, image_r, image_r_gray)",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# SURF\n# stats_kps[0,4],stats_mat[0,4],stats_tdet[0,4],stats_tmat[0,4] = process_SURF(image_l, image_l_gray, image_r, image_r_gray)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Exercise 2: Changes in rotation\nUse `rotate1.png` and `rotate2.png` images.\n\n<img src=\"./images/rotate1.png\" width=\"300\" align=\"left\"/><img src=\"./images/rotate2.png\" width=\"300\" align=\"rigth\"/>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Read images and convert them to gray (will be used for all the methods)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Write your code here!",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Make tests"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# HARRIS + NCC",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# HARRIS + ORB",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ORB",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# SIFT",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# SURF",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Exercise 3: Changes in scale\nUse `scale1.png` and `scale2.png` images.\n\n<img src=\"./images/scale1.png\" width=\"300\" align=\"left\"/><img src=\"./images/scale2.png\" width=\"300\" align=\"rigth\"/>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Write your code here!",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Make tests"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# HARRIS + NCC",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# HARRIS + ORB",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ORB",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# SIFT",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# SURF",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Exercise 4: Changes in point of view\nUse `pov1.png` and `pov2.png` images.\n\n<img src=\"./images/pov1.png\" width=\"300\" align=\"left\"/><img src=\"./images/pov2.png\" width=\"300\" align=\"rigth\"/>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Write your code here!",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Make tests"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# HARRIS + NCC",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# HARRIS + ORB",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ORB",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# SIFT",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# SURF",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Final Graphs\n\nFinally, create a 4x4 bar plot with the results obtained in each test for the number of keypoints (row 1), number of matches (row 2) and timing information (rows 3 and 4) for each method (columns)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Write your code here",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### CONCLUSION\n\n- Are the evaluated methods invariant to these changes?\n- Which one would you use if you had to work with each kind of images?\n- Which one would you use if you needed a real-time system?\n- If there is any method NOT invariant against a certain change, can you think in any solution to make it more robust against this?\n\n**<span style=\"color:blue\">(Answer these questions here!)</span>**"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "591.85px",
        "left": "878.583px",
        "right": "20px",
        "top": "120px",
        "width": "800px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}